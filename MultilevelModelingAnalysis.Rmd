---
title: "Večnivojsko Hiearhično Modeliranje"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
``` {r}
library('lme4')
library('lmerTest')
library('ggplot2')
```

``` {r}
df <- read.csv('data.csv', header=TRUE)
```

Večnivojsko modeliranje je predvsem primerno pri raziskavah, kjer lahko podatke grupiramo po določeni spremenljivki in gre za generalizacijo linearne regresije. Poznamo več vrst različnih modelov: <br />

#### Random intercept model
Predstavlja modele, kjer dovolimo, da se intercepti oz. začetne vrednosti regresijskih premic spreminjajo. Ta model predpostavlja, da so koeficienti premic enaki. Z njim si lahko pomagamo pri računanju ICC oz. intraclass correlation koeficienta, ki pove ali je večnivojsko modeliranje potrebno (tipično vrednosti nad 0.05 nakazujejo, da je večnivojsko modeliranje primerno).

#### Random slopes model
Predstavlja modele, kjer se koeficienti lahko spreminjajo znotraj različnih grup oz. skupin. Ta model predpostavlja, da so začetne vrednosti premic enake.

#### Random intercept and slopes model
Najbolj realističen model, ki vsebuje različne začetne vrednosti kot tudi koeficiente premic v različnih skupinah in je najbolj kompleksen. 

Pri sami izgradnji modelov ni tako pomembno število vnosov znotraj posamezne skupine. Bolj je pomembno je število različnih skupin, ki znaša minimalno 5. 

V našem primeru je najbolj smiselno podatke grupirati po spremenljivki `str_lay_i`. Pri deskriptivni analizi smo namreč opazili, da na kakovost prikaza novic najbolj vpliva izbira določenega pogleda (spremenljivka `layout`) in prisotnost slik (spremenljivka `images`). Spremenljivka `str_lay_i` pa predstavlja niz znakov, doližnine dva (`layout` + `images`), ki pove informacije o trenutem pogledu in ali so slike pristone.
Možne vrednosti spremenljivke `str_lay_i` so torej sledeče:

<ul>
  <li> gw - `gridView` + `withImages` </li>
  <li> ln - `largeCards` + `noImages` </li>
  <li> lw - `largeCards` + `withImages` </li>
  <li> mw - `miniCards` + `withImages` </li>
  <li> xn - `xLargeCards` + `noImages` </li>
  <li> xw - `xLargeCards` + `withImages` </li>
</ul>

Gradnjo modelov bomo začeli pri manj kompleksnih modelih, ki imajo manj parametrov postoma pa bomo dodajali nove. Gradili bomo tako, da bodo čim bolj jasno predstavljene smiselne interakcije. Zgrajene modele bomo primerjali s pomočjo funkcije `anova`. Najboljši model bomo potem primerjali še z ostalimi (Random forest, Bayesov klasifikator, odločitveno drevo, AdaBoost). 

### Izgradnja večnivojskega modela 
Začeli bomo torej s t.i. `random intercept modelom`, ki nam bo povedal, ali je smiselno izvajati večnivojsko modeliranje. V našem primeru smo opazili, da večnivojsko modeliranje je smiselno, saj vrednost ICC znaša 5.611 / (5.611 + 12.385) = 0.312, kar pomeni, da lahko nadaljujemo z večnivojskim modeliranjem, saj do 31% variance prihaja na podlagi izbire pogleda in prisotnosti slik (spremenljivka `str_lay_i`).

Iz izpisa funkcije `summary` lahko sklepamo, da povprečna vrednost ocen pogledov znaša 1.4349 (vrednost spremenljivke `(Intercept)`). 

Na podlagi izpisa funkcije `coefficients` pa opazimo, da imajo pogledi s slikami v splošnem višje ocene, kot tisti brez. To je tudi pričakovano, saj prikazi novic brez slik niso tipični. V današnjih aplikacijah ali spletnih straneh redko beremo novice brez slik, saj te dodajo estetsko vrednost aplikaciji hkrati pa lahko več povejo o novici kot zgolj le besedilo in so v splošnem ljudem bolj zanimive od samega besedila. 

Prav tako opazimo negativne vrednosti pri spremenljivki `xn` (`xLargeCards + noImages`), saj tak način prikaza ni standarden. Po aplikaciji navigiramo s premiki levo-desno in ne z navigacijo gor-dol. Na zaslonu lahko vidimo torej le eno novico, saj se uporabnik lahko tako lažje osredotoči na samo novico. V primeru ko slik torej ni, je na zaslonu podanih premalo informacij (le besedilo). Tako si lahko razložimo, zakaj ima prikaz `largeCards` višje ocene od prikaza `xLargeCards`, ko slik ni, saj ima uporabnik na voljo več informacij, ker je prikazanih več novic hkrati. 

Vrednost 0.003151307 pri spremenljivki `gw` (`gridView + withImages`) prav tako ni presenetljiva, saj uporabniku ponuja premalo informacij na zaslonu, ker ima na voljo le slike s kratkim besedilom o novici. To lahko sklepamo na podlagi tega, da vrednost `mw` (`miniCards + withImages`) ima v povprečju višje ocene.

![gridView With Images](./screenshots/gw.jpg)
![largeCards No Images](./screenshots/ln.jpg)
![largeCards With Images](./screenshots/lw.jpg)
![miniCards With Images](./screenshots/mw.jpg)
![xLargeCards With Images](./screenshots/xw.jpg)
![xLargeCards No Images](./screenshots/xn.jpg)

```{r}
null.model <- lmer(score ~ 1 + (1|str_lay_i), data=df)
summary(null.model)
coefficients(null.model)
```
Na podlagi zgornje analize lahko sklepamo, da so v splošnem uporabnikom bolj všeč pogledi s slikami kot tisti brez.
  
V nadaljevanju si bomo pogledali, kako posamezne spremenljivke na prvem nivoju vplivajo na končno oceno uporabnika. Nato bomo poskušali dodajati interakcije med spremenljivkami

#### Vpliv spremenljivke `user.activity`
Na podlagi spodnjega izpisa lahko vidimo, da v povprečju najslabše ocene dobivajo prikazi novic, ko se uporabnik vozi (vrednost `(Inercept)` znaša -2.3775). Nato pa ocene rastejo, ko se uporabnik sprehaja (vrednost `user.activityON_FOOT` 3.3328) , ko pa je uporabnik pri miru pa daje najvišje ocene (vrednost `user.activitySTILL` 5.2966).

Ta pojav si lahko razložimo tako, da je uporabnik slabše osredotočen na novice, saj ga bolj zanima dogajanje v okolici in si težje nastavi primeren pogled, ki bi mu lahko podal dovolj informacij.


```{r}
user_activity.model <- lmer(score ~ 1 + user.activity + (1|str_lay_i), data=df)
anova(null.model, user_activity.model) # fizicno aktivnost uporabnika moramo upostevati
summary(user_activity.model)
```


#### Vpliv spremenljivke `font.size`
Iz spodnjega modela lahko ugotovimo vpliv velikosti pisave na oceno uporabnika. Opazimo, da je v splošnem ocena manjša, ko ima uporabnik manjšo pisavo (vrednost spremenljivke `font.sizesmall-font` znaša -1.0398). To si lahko razložimo, s tem da je velika pisava bolj razločna in pregledna, saj uporabnik lahko z manj truda prebere novice. Hkrati pa vrednost ni veliko manjša koeficient znaša namreč le -1.0398. V nadaljevanju bomo skušali ugotoviti ali morda fizična aktivnost uporabnika vpliva na izbiro pisave (ko uporabnik hodi je smiselno imeti večjo pisavo medtem ko je pri miru pa ima lahko tudi manjšo, saj se lahko tako lažje osredotoči na aplikacijo). 
```{r}
font_size.model <- lmer(score ~ 1 + font.size + (1|str_lay_i), data=df)
anova(null.model, font_size.model) # velikost pisave moramo upostevati
summary(font_size.model)
```

#### Vpliv spremenljivke `internet.speed`
Za spremenljivko `internet.speed` lahko sklepamo, da ima vpliv (na podlagi modela `internet_speed_effect`). Vrednost ocene uporabnika naj bi padala, ko hitrost internetne povezave raste, vendar si težko razložimo zakaj. Potrebno je omeniti tudi, da je zelo malo takih vnosov, kjer je hitrost internetne povezave enaka 0 (le 45). Prav tako pa je problematično pridobiti več vnosov, ko ima uporabnik zelo počasno internetno povezavo, saj danes to ni več problem. V nadaljavanju bomo pri proučevanju vpliva spremenljivk na končno oceno uporabnika izpustili spremenljivko `internet.speed`.
```{r}
internet_speed_effect <- lmer(score ~ 1 + internet.speed + (1|str_lay_i), data=df)
summary(internet_speed_effect)
```

#### Vpliv spremenljivke `theme`
Na podlagi klica funkcije `summary` lahko sklepamo, da tema vpliva na končno oceno uporabnika, p-vrednost pri koeficentu `themelight-theme` znaša 6.17e-06. Prav tako pa lahko razberemo, da ima v povprečju temna tema aplikacije nižje ocene od svetle. Vrednost koeficienta `themelight-theme` je namreč pozitivna in znaša 1.1003, kar pomeni, da ne glede na to kateri pogled izberemo so ocene višje, ko je nastavljena svetla tema aplikacije.
```{r}
theme_effect <- lmer(score ~ 1 + theme + (1|str_lay_i), data=df)
anova(null.model, theme_effect) # temo moramo upoštevati
summary(theme_effect)
```

#### Vpliv spremenljivke `time.of.day`
Spodnji model nam pove, da so uporabnikove ocene manjše ob bolj poznih urah, saj je vrednost koeficienta `time.of.day` negativna in znaša -0.07844. Razlog za padec ocene bolj kot je pozna ura je lahko ta, da so uporabniki vedno bolj utrujeni in zato dajejo slabše ocene, saj si težje prilagodijo izgled aplikacije. 

Eden izmed parametrov, ki bi lahko vplival na uro je tema aplikacije. Sklepali bi lahko, da je svetlost okolice nižja, bolj kot je pozno. Poslednično pri nižji svetlosti okolice je temna tema aplikacije primernejša. Povezavo med uro in temo aplikacije bomo proučevali v razdelku `Kombinacija vpliva spremenljivk theme in time.of.day`.

Prav tako bi bilo zanimivo proučiti povezavo med uro in velikostjo pisave. Morda bi se lahko izkazalo, da je ob poznejših urah večja pisava boljša, saj so uporabniki bolj utrujeni. Povezavo bomo raziskali v razdelku `Kombinacija vpliva spremenljivk font.size in time.of.day`.

```{r}
time_of_day_effect <- lmer(score ~ 1 + time.of.day + (1|str_lay_i), data=df)
anova(null.model, time_of_day_effect) # uro moramo upoštevati
summary(time_of_day_effect)
```

#### Vpliv spremenljivke `env.brightness`
Na podlagi spodnjega izpisa, lahko sklepamo, da uporabniki dajejo v povprečju višje ocene, manjša kot je svetlost okolice. Vrednost parametra `(Intercept)` znaša 2.5614. Prav tako, ko je svetlost malo višja (vrednost koeficienta `env.brightnessL2` znaša le 0.6476), dajejo uporabniki nekoliko boljše ocene, kar je skoraj zanemarljivo. Potem pa se ocene razlikujejo za višje faktorje (vrednost spremenljivke `env.brightnessL3` znaša -1.2248 pri spremenljivki `env.brightnessL4` pa -2.4363), kar pomeni, da ko je svetlost okolice višja, uporabniki dajejo prikazom slabše ocene. 

V povezavi s svetlostjo okolice, bi bilo najbolje proučiti vpliv spremenljivke `theme`. Sklepali bi namreč lahko, da pri višji svetlosti okolice svetla tema aplikacije prevladuje medtem ko pri nižji temna tema, kar bomo preverili v razdelku `Kombinacija vpliva spremenljivk theme in env.brightness`.  

```{r}
env_brightness_effect <- lmer(score ~ 1 + env.brightness + (1|str_lay_i), data=df)
anova(null.model, env_brightness_effect) # svetlost okolice moramo upoštevati
summary(env_brightness_effect)
```

#### Vpliv spremenljivke `battery.level`
Iz spodnjega modela lahko razberemo, da uporabniki dajejo slabše ocene višji kot je nivo baterije. Vrednost koeficienta `battery.level` je negativna in znaša `-0.051929`. 

V razdelku `Kombinacija vpliva spremenljivk theme in battery.level` bomo podrobneje proučili, kako nivo baterije vpliva na temo aplikacije. V praksi se namreč izkaže, da lahko z uporabo temne barve oz. temne teme aplikacije porabimo manj baterije.  
```{r}
battery_level_effect <- lmer(score ~ 1 + battery.level + (1|str_lay_i), data=df)
anova(null.model, battery_level_effect) # nivo baterije moramo upoštevati
summary(battery_level_effect)
```

#### Vpliv spremenljivke `screen.brightness`
Glede na to, da model slabše napoveduje uporabnikovo oceno, od najbolj osnovnega (`null.model`), bomo v nadaljevanju izpustili spremenljivko `screen.brightness`. Ta bi lahko imela vpliv na temo aplikacije. Njen pomen pa lahko nadomestimo s svetlostjo okolice, saj kot bomo videli v nadaljevanju ima ta velik vpliv na izbiro teme aplikacije.

```{r}
screen_brightness_effect <- lmer(score ~ 1 + screen.brightness + (1|str_lay_i), data=df)
anova(null.model, screen_brightness_effect) # Svetlosti zaslona ni potrebno upoštevati
summary(screen_brightness_effect)
```

#### Kombinacija vpliva spremenljivk `theme` in `time.of.day`
Kot smo omenili si bomo na tem mestu pogledali ali obstaja povezava med temo aplikacije in uro. Iz spodnjih dveh modelov lahko ugotovimo, da interakcije med temo aplikacije in uro ni potrebno upoštevati, saj je model, ki jih upošteva slabši. Sklepamo pa lahko iz spodnjega modela, da je v splošnem svetla tema aplikacije boljša od temne, saj je vrednost koeficienta `themelight-theme` pozitivna in znaša 1.27837. Prav tako pa kot iz prejšnega modela (`time_of_day_effect`), ki pri napovedovanju uporabnikove ocene upošteva le uro, pridemo do istega sklepa. Bolj kot je pozna ura uporabniki dajejo prikazom novic slabše ocene. Vrednost koeficienta `time.of.day` je namreč negativna in znaša -0.09772.

```{r}
# najprej poskusimo, če sploh obstaja interakcija med temo aplikacijo in uro
# to lahko storimo s spodnjima modeloma
time_of_day_theme_no_inter <- lmer(score ~ 1 + theme + time.of.day + (1|str_lay_i), data=df)
time_od_day_theme_with_inter <- lmer(score ~ 1 + theme*time.of.day + (1|str_lay_i), data=df)

# na podlagi spodnje funkcije ugotovimo, da ni potrebno upoštevati interakcije (vrednosti
# AIC in BIC so se namreč povečale, prav tako pa ni statistično relevantne razlike med modeloma
# p vrednost znaša 0.4861) 
# analizirali bomo model brez upoštevanja interakcij
anova(time_of_day_theme_no_inter, time_od_day_theme_with_inter)
summary(time_of_day_theme_no_inter)
```

#### Kombinacija vpliva spremenljivk `theme` in `env.brightness`
Na podlagi spodnjih dveh modelov in klica funkcije anova lahko sklepamo, da moramo upoštevati interakcijo med temo aplikacijo in svetlostjo okolice. Vrednosti `AIC` in `BIC` so manjše pri modelu, ki interakcije med omenjenima spremenljivkama upošteva. Prav tako pa p-vrednost, ki znaša 4.1e-14, nakazuje na statistično relevantno razliko med modeloma. 

Če podrobneje analiziramo torej model, ki interakcije upošteva, pridemo do naslednjih sklepov:

<ul>
  <li> V splošnem ima temna tema aplikacije višje ocene, saj je vrednost parametra `themelight-theme` negativna in znaša -0.3574. Na podlagi njegove p-vrednosti, ki znaša 0.3113 pa lahko sklepamo, da je razlika relativno majhna. </li>
  <li> Še vedno velja, da uporabniki dajejo slabše ocene, ko je svetlost okolice višja, saj so vrednosti parametrov `env.brightnessL3` in `env.brightnessL4` negativne.</li>
  <li> Ne smemo pa zanemariti dejstva da z rastjo svetlosti okolice rastejo tudi ocene za svetlo temo aplikacije. To lahko sklepamo na podlagi vrednosti koeficientov `themelight-theme:env.brightnessL3` in `themelight-theme:env.brightnessL4`, ki so vedno višji. </li>
</ul>

Glavna ugotovitev je, da temna tema aplikacije pridobiva boljše ocene, ko je svetlost okolice nižja, medtem ko priljubljenost svetle teme aplikacije raste, ko raste tudi svetlost okolice.
```{r}
env_brightness_theme_no_inter <- lmer(score ~ 1 + theme + env.brightness + (1|str_lay_i), data=df)
env_brightness_theme_with_inter <- lmer(score ~ 1 + theme*env.brightness + (1|str_lay_i), data=df)
anova(env_brightness_theme_no_inter, env_brightness_theme_with_inter)
summary(env_brightness_theme_with_inter)
```

#### Kombinacija vpliva spremenljivk `theme` in `battery.level`
Iz spodnjih dveh modelov lahko sklepamo, da je potrebno upoštevati interakcijo med temo aplikacije in nivojem baterije. Model, ki jih upošteva je na podlagi klica funkcije `anova` boljši, saj ima manjše vrednosti ocen `AIC` in `BIC`, prav tako pa p-vrednost znaša 0.0005406, kar nakazuje na statistično relevantne razlike med modeloma. 

Podrobnejša analiza modela, ki upošteva interakcije nas pripelje do naslednjih sklepov: 

<ul>
  <li>V splošnem je temna tema aplikacije bolj priljubljena, kar lahko sklepamo na podlagi negativne vrednosti koeficinenta `themelight-theme`, ampak je ta zelo majhna, saj njegova p-vrednost znaša 0.085772.</li>
  <li> Na podlagi koeficienta `battery.level` lahko sklepamo, da ocena pogledov pada, ko se nivo baterije veča </li>
  <li> Ne smemo pa pozabiti, da je vrednost koeficienta `themelight-theme:battery.level` pozitivna in na podlagi p-vrednosti ni zanemarljiva. To pomeni, da z višanjem nivoja baterije pridobivajo boljše ocene pogledi, ki imajo nastavljeno svetlo temo aplikacije.</li>
</ul>

To pomeni, da so enačbe premic, ki napovedujejo oceno uporabnika pridobljene na sledeč način:
<ul>
  <li> Za temno temo aplikacijo velja: 5.124964 + nivo_baterije*(-0.065103)</li>
  <li> Za svetlo temo aplikacije pa: 5.124964 - 1.076953 + nivo_baterije*(-0.065103) + nivo_baterije*0.033259 </li>
</ul>

Če opazujemo zgornji dve enačbi, lahko vidimo, da svetla tema aplikacije začne dobivati večje ali enake vrednosti ocen, ko vrednost nivo_baterije*0.033259 preraste vrednost 1.076953. 

To nas pripelje do naslednje enačbe:
1.076953 = x*0.033259 => x = 1.076953/0.033259 = 32.3808. Kar pomeni, da svetla tema aplikacije začne dobivati boljše ocene, ko ima uporabnik približno več kot 30% baterije, kar je razvideno tudi iz spodnjih grafov. 

Končni sklep je torej, da moramo upoštevati interakcije med nivojem baterije in temo aplikacije, saj tako model boljše napoveduje končne ocene uporabnika. Temna tema aplikacije je boljša, ko je nivo baterije nižji, saj tako lahko uporabniki podaljšajo življensko dobo baterije. Z višjim nivojem baterije (približno nad 30%) pa postane svetlejša tema aplikacije bolj priljubljena. 
```{r}
battery_level_theme_no_inter <- lmer(score ~ 1 + theme + battery.level + (1|str_lay_i), data=df)
battery_level_theme_with_inter <- lmer(score ~ 1 + theme*battery.level + (1|str_lay_i), data=df)
anova(battery_level_theme_no_inter, battery_level_theme_with_inter)
summary(battery_level_theme_with_inter)
(mm_plot <- ggplot(df, aes(x = battery.level, y = score, colour = theme)) +
    facet_wrap(~str_lay_i, nrow=2) +   # a panel for layout_images
    theme_classic() +
    geom_line(data = cbind(df, pred = predict(battery_level_theme_with_inter)), aes(y = pred), size = 1) +  # adding predicted line from mixed model 
    theme(legend.position = "top",
          panel.spacing = unit(2, "lines"))  # adding space between panels
)
```

#### Kombinacija vpliva spremenljivk `font.size` in `time.of.day`
Na podlagi spodnjih modelov lahko sklepamo, da nam ni potrebno upoštevati interakcije med velikostjo pisave in uro. Model, ki omenjenih interakcij ne upošteva ima višje `AIC` in `BIC` vrednosti. Prav tako pa nam `anova` analiza modelov pove, da ni statistično relevantne razlike med modeloma.

Če analiziramo boljši model, lahko sklepamo: 
<ul>
  <li> Boljše ocene, dobivajo pogledi, ki imajo večjo pisavo. To lahko sklepamo na podlagi vrednosti koeficienta `font.sizesmall-font`, ki je negativen in znaša -1.00233</li>
  <li> V splošnem pa ocene padajo bolj kot je pozno, saj je vrednost koeficienta `time.of.day` negativna in znaša -0.07459</li>
</ul>
```{r}
font_size_time_of_day_no_inter <- lmer(score ~ 1 + font.size + time.of.day + (1|str_lay_i), data=df)
font_size_time_of_day_with_inter <- lmer(score ~ 1 + font.size*time.of.day + (1|str_lay_i), data=df)
anova(font_size_time_of_day_no_inter, font_size_time_of_day_with_inter)
summary(font_size_time_of_day_no_inter)
```

#### Kombinacija vpliva spremenljivk `font.size` in `user.activity`
Bolj kot ura vpliva na velikost pisave fizična aktivnost uporabnika, kar nam pove klic funkcije `anova(font_size_time_of_day_no_inter,font_size_user_activity_with_inter)`. Prav tako pa na podlagi klica funkcije `anova(font_size_user_activity_no_inter, font_size_user_activity_with_inter)` lahko ugotovimo, da moramo upoštevati interakcijo med velikostjo pisave in fizično aktivnostjo uporabnika, saj tako lahko boljše napovedujemo uporabniško oceno.

Torej če si podrobneje pogledamo model `font_size_user_activity_with_inter` lahko pridemo do sledečih sklepov:

<ul>
  <li> V povprečju, dajejo uporabniki najslabše ocene med vožnjo. Ocene pa potem rastejo, ko uporabnik hodi ali pa je pri miru.</li>
  <li> V splošnem je prav tako večja pisava bolj priljubljena, saj je vrednost koeficienta `font.sizesmall-font` negativna in znaša -0.06605, kar je blizu nič, saj njegova p-vrednost znaša 0.904112.</li>
  <li> Nato pa se pokažejo razlike med veliko in majhno pisavo, ko uporabnik hodi. Takrat ima manjša pisava manjše vrednosti za faktor, ki znaša kar -2.46884 (vrednost koeficienta `user.activityON_FOOT:font.sizesmall-font`). </li>
  <li> Ko je uporabnik pri miru pa ne obsajajo statistično relevantne razlike med pisavama, saj p-vrednost koeficienta `user.activitySTILL:font.sizesmall-font` znaša 0.544209.</li>
</ul>

Na podlagi spodnjega modela, torej lahko ugotovimo ponovno, da so uporabniki dajali najslabše ocene med vožnjo in boljše ocene, ko so hodili in najboljše, ko so bili pri miru. V splošnem je velika pisava nekoliko bolj priljubljena, a je to skoraj da zanemarljivo Potrebno pa je izbrati ustrezno pisavo, ko uporabnik hodi, saj se na tem mestu izkažejo največje razlike med veliko in majhno pisavo. Med hojo je uporabnikom namreč bolje, če imajo večjo pisavo, saj se tako lahko lažje osredotočijo na branje novic. 
```{r}
font_size_user_activity_no_inter <- lmer(score ~ 1 + user.activity + font.size + (1|str_lay_i), data=df)
font_size_user_activity_with_inter <- lmer(score ~ 1 + user.activity*font.size + (1|str_lay_i), data=df)
anova(font_size_user_activity_no_inter, font_size_user_activity_with_inter)
anova(font_size_time_of_day_no_inter,font_size_user_activity_with_inter)
summary(font_size_user_activity_with_inter)
```

#### Izgradnja končnega modela
Do sedaj smo prišli do sledečih sklepov, ki jih bomo upoštevali pri izgradnji modelov:

<ul>
  <li>V splošnem, ko se spreminja uporabniška aktivnost, se spreminjajo tudi njegove ocene. Uporabniki so namreč najslabše ocene dajali med vožnjo. Nekoliko boljše ocene so dajali med hojo in najboljše, ko so bili pri miru. V kombinaciji s fizično aktivnostjo je na končno oceno predvsem vplivala velikost pisave, kar se najbolj odraža med hojo, saj je imela manjša pisava takrat veliko bolj negativne vrednosti kot večja.</li>
  <li>Na izbiro teme aplikacije najbolj vplivata svetlost okolice in nivo baterije, ki jih moramo upoštevati v interakciji s temo. </li>
  <li>Višji kot je nivo baterije in bolj kot je pozno uporabniki dajejo slabše ocene.</li>
  <li>Na končno oceno uporabnika najmanj vpliva svetlost zaslona, zato jo bomo izpustili.</li>
  <li>Načeloma pri višji hitrosti internetne povezave dajejo uporabniki slabše rezultate, vendar je potrebno omeniti, da je zelo malo takih vnosov, kjer je moč interneta slaba. Prav tako pa je problematično zbirati take vnose, saj uporabniki večinoma nimajo problemov s hitrostjo interneta.</li>
  <li>Na izbiro teme aplikacije in velikostjo pisave ura nima velikega vpliva.</li>
  <li>V splošnem je velika pisava bolj priljubljena kot manjša.</li>
  <li>V splošnem so uporabnikom bolj všeč pogledi s slikami kot tisti brez.</li>
</ul>

V nadaljevanju bomo postopoma dodajali v končni model vse pomembnejše interakcije. Če bomo ob upoštevanju določene spremenljivke dosegali slabše rezultate, jih bomo izpustili. Pri tem si bomo pomagali s klicem funkcije `anova`. Končni model bomo analizirali in si pogledali njegovo učinkovitosti na podlagi k-fold testiranja in vrednosti kot so `f-measure`, `precision`, `recall` ter `accuracy`.

```{r}
# Prvi model bo upošteval interakcije med velikostjo pisave in fizično aktivnostjo uporabnika in temo ter svetlostjo okolice
# te povezave so se namreč izkazale kot pomembnejše
final.model.1 <- lmer(score ~ 1 + user.activity*font.size + theme*env.brightness + (1|str_lay_i), data=df)
# Pri drugem modelu bomo dodali nivo baterije
final.model.2 <- lmer(score ~ 1 + user.activity*font.size + theme*env.brightness + battery.level + (1|str_lay_i), data=df)
anova(final.model.1, final.model.2) # vidimo, da nivo baterije moramo upoštevati
final.model.3 <- lmer(score ~ 1 + user.activity*font.size + theme*env.brightness + theme*battery.level + (1|str_lay_i), data=df)
anova(final.model.2, final.model.3) # vidimo, da interakcijo moramo upoštevati (vrednost AIC manjša), vendar ta ni več tako močna
final.model.4 <- lmer(score ~ 1 + user.activity*font.size + theme*env.brightness + theme*battery.level + time.of.day + (1|str_lay_i), data=df)
anova(final.model.3, final.model.4) # ure nam ni potrebno upoštevati
```

Za končni model bomo izbrali model `final.model.3`.

#### Analiza končnega modela
Na podlagi spodnjega modela lahko pridemo do sledečih sklepov:
<ul>
  <li> Še vedno velja dejstvo, da uporabniki dajejo slabše ocene med vožnjo, nekoliko boljše, ko hodijo in najboljše, ko so pri miru.</li>
  <li> Manjša pisava v aplikaciji je manj priljubljena kot velika, saj je vrednost koeficienta `font.sizesmall-font` negativna in blizu nič, kar lahko sklepamo na podlagi p-vrednosti, ki znaša 0.840859. Največje razlike se pokažejo, ko upoštevamo fizično aktivnost uporabnika.</li>
  <li> Svetla tema aplikacije je načeloma nekoliko slabša, a je tudi ta vrednost zelo majhna in blizu nič, kar lahko sklepamo na podlagi p-vrednosti koeficienta `themelight-theme`. Ne smemo pa zanemariti interakcij med temo aplikacije in svetlostjo okolice. Izkaže se namreč, da se z višanjem svetlosti okolice veča tudi priljubljenost svetle teme aplikacije, kar lahko sklepamo na podlagi vrednosti koeficientov `themelight-theme:env.brightnessL3` in `themelight-theme:env.brightnessL4`. </li>
  <li> V splošnem dajejo uporabniki slabše ocene, ko je svetlost okolice višja, kar vidimo na podlagi negativnih vrednosti koeficientov, `env.brightnessL3` in `env.brightnessL4`, a je to odvisno od izbire teme aplikacije. </li>
  <li>V splošnem velja, da z višanjem nivoja baterije ocene uporabnikov padajo (negativna vrednost koeficienta `battery.level`), vendar pri temu ne smemo pozabiti na izbiro teme v aplikaciji.</li>
  <li>Ko uporabnik hodi, dobiva majhna pisava veliko slabše rezultate kot večja, vrednost koeficienta `user.activityON_FOOT:font.sizesmall-font` je negativna in znaša kar -1.901058. Med vožnjo in ko so uporabniki pri miru pa velikih razlik med majhno in veliko pisavo ni.</li>
  <li>Z višanjem nivoja baterije pa svetla tema aplikacije pridobiva boljše rezultate, kar lahko sklepamo na podlagi vrednosti koeficienta `themelight-theme:battery.level`, ki je pozitiven.</li>
</ul>
```{r}
summary(final.model.3)
```


#### Testiranje končnega modela
S spodnjo funkcijo si bomo pomagali pri ocenjavanju kakovosti modela s pomočjo k-fold testiranja. Testiranje je izvedeno tako, da model napoveduje uporabnikovo oceno, ki je nato primerjana z določenjo vrednostjo, ki jo bomo v nadaljevanju uporabili za razlikovanje med dobrimi in slabimi pogledi. Vse vrednosti, ki so večje ali enake vrednosti oceni 3, se označijo kot pozitivne, v nasprotnem primeru pa kot negativne. S tem dosežemo binarizacijo napovedovanja razreda in jo bomo tudi uporabili pri gradnji in evaluaciji ostalih modelov.  
```{r}
kfold <- function(k){
  set.seed(0)

  shuffled_dataset <-df[sample(nrow(df)),] 

  folds <- cut(seq(1,nrow(shuffled_dataset)),breaks=k,labels=FALSE)
  model_results <- c()
  dummy_results <- c()
  for(i in 1:k){
      testIndexes <- which(folds==i,arr.ind=TRUE)
      testData <- shuffled_dataset[testIndexes, ]
      trainData <- shuffled_dataset[-testIndexes, ]
      final.model.3 <- lmer(score ~ 1 + user.activity*font.size + theme*env.brightness + theme*battery.level + (1|str_lay_i), data=trainData)
      
      counter <- 0
      vecinski <- 0
    
      for(row in 1:nrow(testData)){
        prediction <- predict(final.model.3, testData[row,])
        if( (prediction >= 3 & testData[row,]['score']>=3) || (prediction < 3 & testData[row,]['score']<3) ) {
          counter <- counter + 1
        }
        
        if(testData[row,]['score'] >= 3){
          vecinski <- vecinski + 1
        }
      }
      
      acc_model <- counter/nrow(testData)
      acc_dummy <- vecinski/nrow(testData)
      
      model_results <- c(model_results, acc_model)
      dummy_results <- c(dummy_results, acc_dummy)
  
  }
  
  sprintf("Mean model accuracy = %.2f | Mean dummy model accuracy = %.2f", mean(model_results), mean(dummy_results))
}

```
Na podlagi spodnjega klica lahko razberemo, da ima večnivojski model v povprečju za 6% večjo natančnost pri napovedovanju uporabnikove ocene kot večinski klasifikator.

```{r}
kfold(10)
```

Standardne metrike, ki jih uporabljamo pri evaluaciji modelov so `Accuracy, Precision, Recall, F-measure`. Omenjene metrike lahko izračunamo s pomočjo spodnje funkcije:

```{r}
calcmetrics <- function(tp, fp, fn, tn){
  accuracy <- (tp + tn) / (tp + fp + fn + tn)
  precision <- tp / (tp + fp)
  recall <- tp / (tp + fn)
  fMeasure <- 2 /((1/precision) + (1/recall))
  
  print("==================")
  cat(sprintf("Accuracy = \"%f\"\n ", accuracy))
  cat(sprintf("Precision = \"%f\"\n ", precision))
  cat(sprintf("Recall = \"%f\"\n ", recall))
  cat(sprintf("f-measure = \"%f\"\n ", fMeasure))
}
  
evaluateModel <- function(){
  set.seed(0)
  n_size <- ceiling(836*0.8)
  train_ind <- sample(seq_len(nrow(df)), size = n_size)
  train <- df[train_ind, ]
  test <- df[-train_ind, ]
  final.model.3 <- lmer(score ~ 1 + user.activity*font.size + theme*env.brightness + theme*battery.level + (1|str_lay_i), data=train)

  TP <- 0
  TN <- 0
  
  FP <- 0
  FN <- 0
  
  TP_V <- 0
  FP_V <- 0
  
  FN_V <- 0
  TN_V <- 0
  
  for(row in 1:nrow(test)){
    prediction <- predict(final.model.3, test[row,])
    real_val <- test[row,]['score']
    
    if(prediction >= 3 & real_val>=3){
      TP <- TP + 1
    }
    
    if(prediction < 3 & real_val<3){
      TN <- TN + 1
    }
    
    if(prediction >= 3 & real_val<3){
      FP <- FP +1
    }
    
    if(prediction < 3 & real_val>=3){
      FN <- FN + 1
    }
    
    if(real_val >= 3){
      TP_V <- TP_V + 1
    }else{
      FP_V <- FP_V + 1
    }
    
  }

  calcmetrics(TP, FP, FN, TN)
  calcmetrics(TP_V, FP_V, FN_V, TN_V)  
}
```

Iz spodnjega izpisa lahko ugotovimo, da je novozgrajen model boljši, vendar je problem, da velikokrat napove negativen razred, čeprav je ta bil pozitiven (vrednost `recall` manjša). Izkaže pa se, da se modelu poveča natančnost (`accuracy` znaša 0.77). Prav tako pa model redkeje zgreši negativen razred, ko napove pozitiven izhod (mera `precision` je večja).

V splošnem želimo maksimizirati obe vrednosti (`precision` in `recall`), zato uporabimo mero `f-measure`. V našem primeru vidimo, da smo dosegli manjši napredek, saj vrednost `f-measure` znaša 0.807882 medtem ko pri večinskem klasifikatorju 0.794224. To pomeni, da smo dosegli nekoliko boljše razmerje med vrednostima `recall` in `precision` v primerjavi z večinskim klasifikatorjem.
```{r}
evaluateModel()
```



